{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VpWHxPBPJLo"
      },
      "source": [
        "!pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucTLSDidPTnT"
      },
      "source": [
        "!pip install torch-sparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRghJwHSPZ_r"
      },
      "source": [
        "!pip install torch-scatter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYHvzpfUPbJu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import InMemoryDataset\n",
        "from tqdm import tqdm\n",
        "from torch.nn import Sequential as Seq, Linear, ReLU\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
        "from torch_geometric.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO83a7yQPgN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b568d3b-45f4-4d39-c90c-704c8b2ce57b"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/data/yoochoose-clicks.dat', header=None)\n",
        "df.columns=['session_id','timestamp','item_id','category']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpofvJ51TuKX"
      },
      "source": [
        "buy_df = pd.read_csv('/content/drive/MyDrive/data/yoochoose-buys.dat', header=None)\n",
        "buy_df.columns=['session_id','timestamp','item_id','price','quantity']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5lEXIeVWNsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b091ec4-540f-4e32-a839-ff89c66603d9"
      },
      "source": [
        "df.nunique()\n",
        "buy_df.nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "session_id     509696\n",
              "timestamp     1136477\n",
              "item_id         19949\n",
              "price             735\n",
              "quantity           28\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3KX8QFzWoBU"
      },
      "source": [
        "sampled_session_id = np.random.choice(df.session_id.unique(), 50000, replace=False)\n",
        "df = df.loc[df.session_id.isin(sampled_session_id)]\n",
        "df.nunique()\n",
        "df.isna().sum()\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "def preprocess(dataframe,col):\n",
        "    encoder = LabelEncoder()\n",
        "    dataframe[col] = encoder.fit_transform(dataframe[col])\n",
        "preprocess(df,\"item_id\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6AH1mmfWx4g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9f603ae0-f102-48f5-a203-1b8e3fd65852"
      },
      "source": [
        "df['label'] = df.session_id.isin(buy_df.session_id)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>item_id</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>820</th>\n",
              "      <td>256</td>\n",
              "      <td>2014-04-07T14:16:36.706Z</td>\n",
              "      <td>11437</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>821</th>\n",
              "      <td>256</td>\n",
              "      <td>2014-04-07T14:17:57.517Z</td>\n",
              "      <td>11437</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>822</th>\n",
              "      <td>256</td>\n",
              "      <td>2014-04-07T14:18:25.346Z</td>\n",
              "      <td>10533</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>256</td>\n",
              "      <td>2014-04-07T14:18:34.007Z</td>\n",
              "      <td>11415</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1328</th>\n",
              "      <td>468</td>\n",
              "      <td>2014-04-01T19:40:28.301Z</td>\n",
              "      <td>11424</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      session_id                 timestamp  item_id category  label\n",
              "820          256  2014-04-07T14:16:36.706Z    11437        0  False\n",
              "821          256  2014-04-07T14:17:57.517Z    11437        0  False\n",
              "822          256  2014-04-07T14:18:25.346Z    10533        0  False\n",
              "823          256  2014-04-07T14:18:34.007Z    11415        0  False\n",
              "1328         468  2014-04-01T19:40:28.301Z    11424        0  False"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYAhF1muW4LH"
      },
      "source": [
        "class YooChooseBinaryDataset(InMemoryDataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        super(YooChooseBinaryDataset, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return []\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['/content/drive/MyDrive/data/yoochoose_click_binary_1M_sess.dataset']\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "    \n",
        "    def process(self):\n",
        "        \n",
        "        data_list = []\n",
        "\n",
        "        # process by session_id\n",
        "        grouped = df.groupby('session_id')\n",
        "        for session_id, group in tqdm(grouped):\n",
        "            sess_item_id = LabelEncoder().fit_transform(group.item_id)\n",
        "            group = group.reset_index(drop=True)\n",
        "            group['sess_item_id'] = sess_item_id\n",
        "            node_features = group.loc[group.session_id==session_id,['sess_item_id','item_id']].sort_values('sess_item_id').item_id.drop_duplicates().values\n",
        "\n",
        "            node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
        "            target_nodes = group.sess_item_id.values[1:]\n",
        "            source_nodes = group.sess_item_id.values[:-1]\n",
        "\n",
        "            edge_index = torch.tensor([source_nodes,\n",
        "                                   target_nodes], dtype=torch.long)\n",
        "            x = node_features\n",
        "\n",
        "            y = torch.FloatTensor([group.label.values[0]])\n",
        "\n",
        "            data = Data(x=x, edge_index=edge_index, y=y)\n",
        "            data_list.append(data)\n",
        "        \n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzORPNtTW87U"
      },
      "source": [
        "dataset = YooChooseBinaryDataset(root='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t4CTs0Sb8Kd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66e8ad0-9ad7-436e-e73b-d1bfb0a8680b"
      },
      "source": [
        "##Shuffling and splitting the dataset\n",
        "dataset = dataset.shuffle()\n",
        "train_dataset = dataset[:30000]\n",
        "val_dataset = dataset[30000:40000]\n",
        "test_dataset = dataset[40000:]\n",
        "len(train_dataset), len(val_dataset), len(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itBEJhnocCfD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3399648e-7ae0-4aa2-8037-d1da5840cda0"
      },
      "source": [
        "#loading the data using loader function\n",
        "batch_size= 1024\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2lvhSLvcaRA"
      },
      "source": [
        "class SAGEConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(SAGEConv, self).__init__(aggr='max') #  \"Max\" aggregation.\n",
        "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
        "        self.act = torch.nn.ReLU()\n",
        "        self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=False)\n",
        "        self.update_act = torch.nn.ReLU()\n",
        "        \n",
        "    def forward(self, x, edge_index):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "        \n",
        "        \n",
        "        edge_index, _ = remove_self_loops(edge_index)\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "        \n",
        "        \n",
        "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
        "\n",
        "    def message(self, x_j):\n",
        "        # x_j has shape [E, in_channels]\n",
        "\n",
        "        x_j = self.lin(x_j)\n",
        "        x_j = self.act(x_j)\n",
        "        \n",
        "        return x_j\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        # aggr_out has shape [N, out_channels]\n",
        "\n",
        "\n",
        "        new_embedding = torch.cat([aggr_out, x], dim=1)\n",
        "        \n",
        "        new_embedding = self.update_lin(new_embedding)\n",
        "        new_embedding = self.update_act(new_embedding)\n",
        "        \n",
        "        return new_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znx9mCVIcfEv"
      },
      "source": [
        "#create NN\n",
        "embed_dim = 128\n",
        "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "import torch.nn.functional as F\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(embed_dim, 128)\n",
        "        self.pool1 = TopKPooling(128, ratio=0.8)\n",
        "        self.conv2 = SAGEConv(128, 128)\n",
        "        self.pool2 = TopKPooling(128, ratio=0.8)\n",
        "        self.conv3 = SAGEConv(128, 128)\n",
        "        self.pool3 = TopKPooling(128, ratio=0.8)\n",
        "        self.conv4 = SAGEConv(128, 128)\n",
        "        self.pool4 = TopKPooling(128, ratio=0.8)\n",
        "        self.item_embedding = torch.nn.Embedding(num_embeddings=df.item_id.max() +1, embedding_dim=embed_dim)\n",
        "        self.lin1 = torch.nn.Linear(256, 128)\n",
        "        self.lin2 = torch.nn.Linear(128, 64)\n",
        "        self.lin3 = torch.nn.Linear(64, 1)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
        "        self.act1 = torch.nn.ReLU()\n",
        "        self.act2 = torch.nn.ReLU()        \n",
        "  \n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.item_embedding(x)\n",
        "        x = x.squeeze(1)        \n",
        "\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _,_ = self.pool1(x, edge_index, None, batch)\n",
        "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "     \n",
        "        x, edge_index, _, batch, _,_ = self.pool2(x, edge_index, None, batch)\n",
        "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _,_ = self.pool3(x, edge_index, None, batch)\n",
        "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = F.relu(self.conv4(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _,_ = self.pool4(x, edge_index, None, batch)\n",
        "        x4 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = x1 + x2 + x3 +x4\n",
        "\n",
        "        x = self.lin1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.act2(x)      \n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC14cxE2cjWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c130ae-aa2d-4266-dbdd-c91452a97b36"
      },
      "source": [
        "#view data\n",
        "for data in train_dataset:\n",
        "    print(data)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[3, 1], edge_index=[2, 2], y=[1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz8hz0j0cksK"
      },
      "source": [
        "device = torch.device('cpu')\n",
        "model = Net().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "crit = torch.nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsykmgXycmbl"
      },
      "source": [
        "##train network\n",
        "def train():\n",
        "    model.train()\n",
        "    loss_all = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        label = data.y.to(device)\n",
        "        loss = crit(output, label)\n",
        "        loss.backward()\n",
        "        loss_all += data.num_graphs * loss.item()\n",
        "        optimizer.step()\n",
        "    return loss_all / len(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGlz9Qsyc0Jt"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "\n",
        "            data = data.to(device)\n",
        "            pred = model(data).detach().cpu().numpy()\n",
        "\n",
        "            label = data.y.detach().cpu().numpy()\n",
        "            predictions.append(pred)\n",
        "            labels.append(label)\n",
        "\n",
        "    predictions = np.hstack(predictions)\n",
        "    labels = np.hstack(labels)\n",
        "    \n",
        "    return roc_auc_score(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-HfzNd8c13n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb7d068-8adc-45fb-d78c-685ef37edcf6"
      },
      "source": [
        "for epoch in range(20):\n",
        "    loss = train()\n",
        "    train_acc = evaluate(train_loader)\n",
        "    val_acc = evaluate(val_loader)    \n",
        "    test_acc = evaluate(test_loader)\n",
        "    print('Epoch: {:03d}, Loss: {:.5f}, Train Auc: {:.5f}, Val Auc: {:.5f}, Test Auc: {:.5f}'.\n",
        "          format(epoch, loss, train_acc, val_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 0.06037, Train Auc: 0.99351, Val Auc: 0.61986, Test Auc: 0.61250\n",
            "Epoch: 001, Loss: 0.05380, Train Auc: 0.99378, Val Auc: 0.63745, Test Auc: 0.63070\n",
            "Epoch: 002, Loss: 0.04834, Train Auc: 0.99139, Val Auc: 0.64678, Test Auc: 0.64062\n",
            "Epoch: 003, Loss: 0.05368, Train Auc: 0.99276, Val Auc: 0.63718, Test Auc: 0.63110\n",
            "Epoch: 004, Loss: 0.05693, Train Auc: 0.98596, Val Auc: 0.64484, Test Auc: 0.63699\n",
            "Epoch: 005, Loss: 0.05614, Train Auc: 0.99115, Val Auc: 0.63681, Test Auc: 0.63186\n",
            "Epoch: 006, Loss: 0.06619, Train Auc: 0.99248, Val Auc: 0.62115, Test Auc: 0.61789\n",
            "Epoch: 007, Loss: 0.07584, Train Auc: 0.99210, Val Auc: 0.59790, Test Auc: 0.59246\n",
            "Epoch: 008, Loss: 0.06502, Train Auc: 0.99394, Val Auc: 0.59316, Test Auc: 0.58873\n",
            "Epoch: 009, Loss: 0.04729, Train Auc: 0.99608, Val Auc: 0.61764, Test Auc: 0.61189\n",
            "Epoch: 010, Loss: 0.03502, Train Auc: 0.99676, Val Auc: 0.60956, Test Auc: 0.60600\n",
            "Epoch: 011, Loss: 0.03269, Train Auc: 0.99685, Val Auc: 0.61260, Test Auc: 0.60829\n",
            "Epoch: 012, Loss: 0.03073, Train Auc: 0.99722, Val Auc: 0.60919, Test Auc: 0.60442\n",
            "Epoch: 013, Loss: 0.03333, Train Auc: 0.99499, Val Auc: 0.61642, Test Auc: 0.61364\n",
            "Epoch: 014, Loss: 0.03868, Train Auc: 0.99700, Val Auc: 0.61054, Test Auc: 0.60650\n",
            "Epoch: 015, Loss: 0.03100, Train Auc: 0.99718, Val Auc: 0.61141, Test Auc: 0.60606\n",
            "Epoch: 016, Loss: 0.02934, Train Auc: 0.99735, Val Auc: 0.61064, Test Auc: 0.60984\n",
            "Epoch: 017, Loss: 0.02873, Train Auc: 0.99734, Val Auc: 0.61249, Test Auc: 0.61043\n",
            "Epoch: 018, Loss: 0.02897, Train Auc: 0.99726, Val Auc: 0.61520, Test Auc: 0.61538\n",
            "Epoch: 019, Loss: 0.02846, Train Auc: 0.99727, Val Auc: 0.61427, Test Auc: 0.61192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntCLN0WrTqmd"
      },
      "source": [
        ""
      ]
    }
  ]
}